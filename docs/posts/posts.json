[
  {
    "path": "posts/2024-10-10-best-rainfall-prediction-model-based-on-skill-score/",
    "title": "Best Rainfall Prediction Model Based on Skill Score",
    "description": "This content contains information and techniques in determining the best prediction model using the skill score method.",
    "author": [
      {
        "name": "Eggy Pandiangan",
        "url": {}
      }
    ],
    "date": "2024-10-10",
    "categories": [],
    "contents": "\r\n\r\nContents\r\n1. INTRODUCTION\r\nDefinition and Goals of Climate Seasonal Forecast Assessment\r\nExamples of Evaluations for Climate Seasonal Forecasts\r\n\r\n2. HOW IT IS EVALUATED?\r\nApproaches for Assessing Climate Seasonal Forecast\r\nSkill Score Method\r\n\r\n3. RAINFALL PREDICTION EVALUATION (FOR SEASON ONSET DETERMINATION)\r\nAssessment at ZOM 9120\r\nUsing the Skill Score method to Interpret the Evaluation\r\n\r\n4. RAINFALL WEIGHTING\r\nSeasonal Rainfall Prediction Weighting based on Skill Score\r\nSeasonal Rainfall Prediction ZOM 9120 using Skill Score-based weighting\r\n\r\n\r\n1. INTRODUCTION\r\nDefinition and Goals of Climate Seasonal Forecast Assessment\r\n\r\nA Climate Seasonal Forecast Assessment refers to the systematic evaluation of seasonal climate forecasts, which typically predict weather patterns over several months. This process involves analyzing the accuracy, skill, and reliability of these forecasts to determine how closely they match the actual weather outcomes (observation). The primary goal of this assessment is to verify whether the forecasted seasonal conditions, such as temperature, precipitation, and wind patterns, align with the observed climate data for the given period.\r\n\r\n\r\nThe verification aspect plays a crucial role in this assessment, as it measures the forecast’s skill and consistency. Verification involves comparing the predicted values with real-world data, often using statistical techniques to determine the forecast’s accuracy. The results of the verification help meteorologists refine forecasting models, identify areas for improvement, and better understand the underlying climatic variables that influence seasonal patterns. Validation is the confirmation through testing and providing objective evidence that certain requirements for a specific purpose are met by a model. Verification, on the other hand, is the process of comparing model calculations (forecasts) with actual values (observations), which is generally equated with validation (Jolliffe and Stephenson 2011).\r\n\r\n\r\nThe type of verification adjusts to the type of forecasts, here are some examples of the types of forecasts and verification (WWRP 2017)\r\n\r\n\r\nNature of forecast:\r\n\r\n\r\nExample(s):\r\n\r\n\r\nVerification methods:\r\n\r\n\r\ndeterministic (non-probabilistic)\r\n\r\n\r\nquantitative precipitation forecast\r\n\r\n\r\nvisual, dichotomous, multi-category, continuous, spatial\r\n\r\n\r\nprobabilistic\r\n\r\n\r\nprobability of precipitation, ensemble forecast\r\n\r\n\r\nvisual, probabilistic, ensemble\r\n\r\n\r\nqualitative (worded)\r\n\r\n\r\n5-day outlook\r\n\r\n\r\nvisual, dichotomous, multi-category\r\n\r\n\r\nSpace-time domain:\r\n\r\n\r\n\r\n\r\n\r\n\r\ntime series\r\n\r\n\r\ndaily maximum temperature forecasts for a city\r\n\r\n\r\nvisual, dichotomous, multi-category, continuous, probabilistic\r\n\r\n\r\nspatial distribution\r\n\r\n\r\nmap of geopotential height, rainfall chart\r\n\r\n\r\nvisual, dichotomous, multi-category, continuous, probabilistic, spatial, ensemble\r\n\r\n\r\npooled space and time\r\n\r\n\r\nmonthly average global temperature anomaly\r\n\r\n\r\ndichotomous, multi-category, continuous, probabilistic, ensemble\r\n\r\n\r\nSpecificity of forecast:\r\n\r\n\r\n\r\n\r\n\r\n\r\ndichotomous (yes/no)\r\n\r\n\r\noccurrence of fog\r\n\r\n\r\nvisual, dichotomous, probabilistic, spatial, ensemble\r\n\r\n\r\nmulti-category\r\n\r\n\r\ncold, normal, or warm conditions\r\n\r\n\r\nvisual, multi-category, probabilistic, spatial, ensemble\r\n\r\n\r\ncontinuous\r\n\r\n\r\nmaximum temperature\r\n\r\n\r\nvisual, continuous, probabilistic, spatial, ensemble\r\n\r\n\r\nobject- or event-oriented\r\n\r\n\r\ntropical cyclone motion and intensity\r\n\r\n\r\nvisual, dichotomous, multi-category, continuous, probabilistic, spatial\r\n\r\n\r\nAllan Murphy (Murphy 1993), a pioneer in the field of prediction verification, distinguishes 3 types of ‘goodness’ of a prediction :\r\nConsistency - the degree to which the forecast corresponds to the forecaster’s best judgement about the situation, based upon his/her knowledge base.\r\nQuality - the degree to which the forecast corresponds to what actually happened (observation).\r\nValue - the degree to which the forecast helps a decision maker to realize some incremental economic and/or other benefit.\r\n\r\nIn addition, Murphy also mentioned that there are 8 aspects (attributes) that show the quality of a forecast, including:\r\n\r\nNo.\r\n\r\n\r\nAspects/Attributes\r\n\r\n\r\nDescription\r\n\r\n\r\nScores/metrics that can be used\r\n\r\n\r\n1\r\n\r\n\r\nBias\r\n\r\n\r\nDifference between predicted and observed means\r\n\r\n\r\nMean Error (ME), Mean Square Error (MSE), Scatter plot\r\n\r\n\r\n2\r\n\r\n\r\nAccuracy\r\n\r\n\r\nThe degree of agreement between prediction and observation\r\n\r\n\r\nContinuous Rank Probability Score (CRPS), Taylor Diagram\r\n\r\n\r\n3\r\n\r\n\r\nUncertainty\r\n\r\n\r\nThe diversity of observation values, the greater the uncertainty of the observation, the more difficult it is to predict\r\n\r\n\r\nVerification Rank Histogram (VRH)\r\n\r\n\r\n4\r\n\r\n\r\nSharpness\r\n\r\n\r\nThe ability of the forecast to predict extreme values. Sharpness is “only” possessed by predictions (not observations); even poor predictions still have the attribute of sharpness\r\n\r\n\r\nEnsemble Spread (SPRD), Spread Skill Relationship (SSR)\r\n\r\n\r\n5\r\n\r\n\r\nResolution\r\n\r\n\r\nThe ability of a forecast to represent how much the prediction differs from the probabilistic mean of the climatology of an event and whether the prediction system can predict it correctly; Typically used to measure the mean square of probabilistic prediction error\r\n\r\n\r\nBrier Score (BS), Relative Operating Characteristic (ROC)\r\n\r\n\r\n6\r\n\r\n\r\nDiscrimination\r\n\r\n\r\nThe forecast’s ability to clearly distinguish a situation that leads to the occurrence or non-occurrence of an event\r\n\r\n\r\nRelative Operating Characteristic (ROC)\r\n\r\n\r\n7\r\n\r\n\r\nReliability\r\n\r\n\r\nStatistical consistency between the probabilistic prediction of an event and the actual frequency of occurrence\r\n\r\n\r\nReliability Diagram (RD), Brier Score (BS)\r\n\r\n\r\n8\r\n\r\n\r\nSkill\r\n\r\n\r\nThe relative accuracy of a prediction model to a reference (climatological conditions) or an increase in prediction accuracy due to an improved prediction system; Skill is used to measure the superiority of a prediction system based on a baseline of past observations\r\n\r\n\r\nSkill Score (SS): BSS, CRPSS, ROCSS\r\n\r\nExamples of Evaluations for Climate Seasonal Forecasts\r\n\r\nSome meteorological agencies in other countries have evaluated their predictions using several verification metrics, for example:\r\n\r\n\r\n\r\n\r\n\\(~\\)\r\n2. HOW IT IS EVALUATED?\r\nApproaches for Assessing Climate Seasonal Forecast\r\n\r\nThere are several approaches that are commonly used to assess seasonal climate forecasts (Wilks 2011; Jolliffe and Stephenson 2011; WWRP 2017), such as:\r\n\r\n\r\nNo.\r\n\r\n\r\nMetric\r\n\r\n\r\nFormulation\r\n\r\n\r\nDescription\r\n\r\n\r\n1\r\n\r\n\r\nMean Error (ME)\r\n\r\n\r\n\\(\\text{ME}=\\frac{\\sum_{i=1}^{n}\\left(f_i-o_i\\right)}{n}\\)\r\n\r\n\r\n\\(n=\\) Number of data pairs (forecast & observation); \\(f_i=\\) Forecast value; \\(o_i=\\) Observatioin value; Best Score \\(=0\\); Verification method = continuous;\r\n\r\n\r\n2\r\n\r\n\r\nMean Absolute Error (MAE)\r\n\r\n\r\n\\(\\text{MAE}=\\frac{\\sum_{i=1}^{n}\\left|f_i-o_i\\right|}{n}\\)\r\n\r\n\r\n\\(n=\\) Number of data pairs (forecast & observation); \\(f_i=\\) Forecast value; \\(o_i=\\) Observatioin value; Best Score \\(=0\\); Verification method = continuous;\r\n\r\n\r\n3\r\n\r\n\r\nRoot Mean Square Error (RMSE)\r\n\r\n\r\n\\(\\text{RMSE}=\\sqrt{\\frac{\\sum_{i=0}^{N - 1} (f_i - o_i)^2}{N}}\\)\r\n\r\n\r\n\\(N=\\) Number of data pairs (forecast & observation); \\(f_i=\\) Forecast value; \\(o_i=\\) Observatioin value; Best Score \\(=0\\); Verification method = continuous;\r\n\r\n\r\n4\r\n\r\n\r\nBoxplot\r\n\r\n\r\n\r\n\r\n\\(Q_1=(n+1)*0.25\\); \\(Q_2=(n+1)*0.5\\); \\(Q_3=(n+1)*0.75\\); \\(IQR=Q_3-Q_1\\); Best Score = Closest to Observation; Verification method = continuous, visual;\r\n\r\n\r\n5\r\n\r\n\r\nScatter plot\r\n\r\n\r\n\r\n\r\nBest Score = gather around the diagonal; Verification method = continuous, visual;\r\n\r\n\r\n6\r\n\r\n\r\nCorrelation Coefficient \\((r)\\)\r\n\r\n\r\n\\(r=\\frac{\\sum{(f_i-\\overline{f})(o_i-\\overline{o})}}{\\sqrt{\\sum{(f_i-\\overline{f})^2}}\\sqrt{\\sum{(o_i-\\overline{o})^2}}}\\)\r\n\r\n\r\n\\(f_i=\\) i-th forecast value; \\(\\overline{f}=\\) mean of forecast values; \\(o_i=\\) i-th observation value; \\(\\overline{f}=\\) mean of observation values; Best Score = 1; Verification method = continuous;\r\n\r\n\r\n7\r\n\r\n\r\nDichotomous Contingency Table\r\n\r\n\r\n\r\n\r\n\\(\\text{HR} = \\frac{a}{a + c} = \\hat{p}(\\hat{x} = 1 \\mid x = 1)\\); \\(\\text{PC or Accuracy} = \\frac{a + d}{n} = \\hat{p}\\left[(\\hat{x} = 1, x = 1) \\, \\text{or} \\, (\\hat{x} = 0, x = 0)\\right]\\);\\(\\text{FAR} = \\frac{b}{a + b} = \\hat{p}(x = 0 \\mid \\hat{x} = 1)\\); \\(\\text{CSI} = \\frac{a}{a + b + c}\\);ROC\r\n\r\n\r\n8\r\n\r\n\r\nMulti-Category Contingency Table\r\n\r\n\r\n\r\n\r\n\\(\\text{Accuracy} = \\frac{1}{N} \\sum_{i=1}^{K}n(F_i, O_i)\\); \\(\\text{HSS} = \\frac{\\frac{1}{N} \\sum_{i=1}^{K} n(F_i, O_i)-\\frac{1}{N^2} \\sum_{i=1}^{K} N(F_i) N(O_i)}{1 - \\frac{1}{N^2} \\sum_{i=1}^{K} N(F_i) N(O_i)}\\);   Best Score Accuracy=1; Best Score HSS=1\r\n\r\nSkill Score Method\r\n\r\nPrediction of the onset of the Indonesian season by BMKG for both the wet and dry seasons is based on rainfall values obtained from the output of several models. These models consist of dynamic and statistical models that have their own advantages and disadvantages. The number of models used will certainly cause more uncertainty in the prediction of season onset. To overcome this, several things can be done :\r\n\r\nUse the ensemble mean of all rainfall models and then determine the onset of the season (at ZOM area);\r\nUsing the season onset mode from all models at the ZOM area;\r\nUsing the best model output in the ZOM area, and the best model can be found with:\r\nModel evaluation based on historical predictions and observations of season onset\r\nModel evaluation based on historical prediction and observation of rainfall\r\n\r\n\r\nSome of the metrics previously described can be used to evaluate the rainfall output of models used in seasonal prediction. Here we will use an evaluation metric called the Taylor Skill Score (TSS)(Xiaoli Yang and Sheffield 2020) or commonly called Skill Score (SS), whose basis is the Taylor Diagram. The Taylor Diagram has 3 output results (Correlation Coefficient, RMSE, and \\({NSD}_m\\)) drawn in one graph. If referring to each of the Taylor Diagram outputs, it will certainly be difficult to determine the best model. TSS combines the 3 outputs that produce a value that states the skill of the rainfall prediction model being evaluated.\r\n\r\n\\[\\begin{equation}\r\n\\tag{1}\r\nSS = \\frac{4(1 + CC)^4}{\\left( \\text{NSD}_m + \\frac{1}{\\text{NSD}_m} \\right)^2 (1 + CC_0)^4}\r\n\\end{equation}\\]\r\n\\[\\begin{equation}\r\n\\tag{2}\r\n\\text{NSD}_m = \\frac{\\sigma_{\\text{mod}}}{\\sigma_{\\text{obs}}}\r\n\\end{equation}\\]\r\nWhere:\r\n\\[\r\n\\text{NSD}_m = \\text{Normalized standard deviation of the simulation (model)}\r\n\\]\r\n\\[\r\n\\sigma_{\\text{mod}} = \\text{Standard deviation of the simulation (model)}\r\n\\]\r\n\\[\r\n\\sigma_{\\text{obs}} = \\text{Standard deviation of the observation}\r\n\\]\r\n\\[\r\nm = \\text{Model value simulation}\r\n\\]\r\n\\[\r\n\\text{CC}_0 = \\text{Maximum correlation coefficient usually 1}\r\n\\]\r\n\\[\r\n\\text{CC} = \\text{Correlation coefficient between the simulated (model) and observed data}\r\n\\]\r\n\r\nThe closer SS is to 1, the better the ability of the individual model to represent the observations\r\n\r\n\\(~\\)\r\n3. RAINFALL PREDICTION EVALUATION (FOR SEASON ONSET DETERMINATION)\r\nAssessment at ZOM 9120\r\n\r\nHere is an example of rainfall forecast data from several models (Initial January 2011) and observations, for 21 dekad days (ZOM Aceh_01):\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nCODE TO CREATE A TAYLOR DIAGRAM\r\n\r\n\r\n\r\nlibrary(openair)\r\nlibrary(tidyverse)\r\n#data <- read.csv('path/to/your/data.csv')\r\nt_dt3 <- pivot_longer(data = data, cols = colnames(data[!colnames(data) %in% c('Jan_2011','OBS')]), names_to = 'MODEL', values_to = 'CH')\r\nt_dt3$MODEL <- factor(t_dt3$MODEL, levels = unique(t_dt3$MODEL))\r\np2 <- TaylorDiagram(t_dt3, obs = \"OBS\", mod = \"CH\", group = \"MODEL\", normalise = T, cols = c('cornflowerblue','blue','yellow2','deeppink','deeppink4','orange1','orange4'),\r\n                    text.obs = 'Observasi', key = T, main=paste0('Taylor Diagram'))\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nECMWF_RAW\r\n\r\n\r\nECMWF_COR\r\n\r\n\r\nMME1\r\n\r\n\r\nCFSv2_RAW\r\n\r\n\r\nCFSv2_COR\r\n\r\n\r\nARIMA\r\n\r\n\r\nWARIMA\r\n\r\n\r\nRMSE\r\n\r\n\r\n42.9393894\r\n\r\n\r\n32.8570424\r\n\r\n\r\n38.5247122\r\n\r\n\r\n46.4539831\r\n\r\n\r\n31.4249754\r\n\r\n\r\n43.5126742\r\n\r\n\r\n42.0122118\r\n\r\n\r\nCC\r\n\r\n\r\n0.6972082\r\n\r\n\r\n0.7312276\r\n\r\n\r\n0.5420013\r\n\r\n\r\n0.4109492\r\n\r\n\r\n0.7422360\r\n\r\n\r\n0.3165167\r\n\r\n\r\n0.4026214\r\n\r\n\r\nNSDm\r\n\r\n\r\n0.6112191\r\n\r\n\r\n0.5841298\r\n\r\n\r\n0.6217545\r\n\r\n\r\n0.6297243\r\n\r\n\r\n0.7395452\r\n\r\n\r\n0.3083050\r\n\r\n\r\n0.3535605\r\n\r\n\r\nSS\r\n\r\n\r\n0.4107342\r\n\r\n\r\n0.4259743\r\n\r\n\r\n0.2842024\r\n\r\n\r\n0.2014521\r\n\r\n\r\n0.5264507\r\n\r\n\r\n0.0595302\r\n\r\n\r\n0.0955697\r\n\r\n\r\nW\r\n\r\n\r\n0.2049660\r\n\r\n\r\n0.2125712\r\n\r\n\r\n0.1418237\r\n\r\n\r\n0.1005293\r\n\r\n\r\n0.2627113\r\n\r\n\r\n0.0297070\r\n\r\n\r\n0.0476915\r\n\r\n\r\n\r\nBased on the above example, the best model in ZOM ACEH_01 for the January 2011 prediction initial is the CFSv2_COR Model. SS calculations should be carried out throughout the availability of data (in this example from 2011 - 2020) and the entire initial (January - December). So that the SS will be obtained for each month (January - December) for 10 years (2011 - 2020). Based on all the SS obtained, the average SS for the 10 years can be calculated and the best model with the highest SS is obtained.\r\n\r\n\r\nBEST MODEL FOR EACH ZOM BASED ON AVERAGE SS 2011-2020\r\n\r\n\r\n\r\nSelect Metric:\r\n\r\n\r\n\r\n\r\nSelect Init:\r\n\r\n\r\n\r\n\r\n\r\nUsing the Skill Score method to Interpret the Evaluation\r\n\r\nBased on the highest Skill Score (maximum 1), we will get the best model in each ZOM for each initial release. From the tabular results above, we can display the Skill Score value and the best model for each ZOM spatially.\r\n\r\n\r\nBEST MODEL FOR EACH ZOM BASED ON AVERAGE SS 2011-2020 ON INITIAL JANUARY\r\n\r\n\r\n\r\n\r\n\r\n\r\nThen, we can also see the distribution of Skill Scores for 10 years (2011-2020) using boxplot to find out what the dominant skill score is.\r\n\r\n\r\nEXAMPLE OF SKILL SCORE DISTRIBUTION IN SEVERAL ZOMS IN A GIVEN MONTH (2011-2020)\r\n\r\n\r\n\r\n\r\n\r\nSS FOR 2011-2020 AT ZOM\r\n\r\n\r\n\r\n\r\n\r\nCODE TO CREATE A BOXPLOT\r\n\r\n\r\n\r\n#ss_aceh01 <- read.csv('path/to/your/data.csv')\r\nplot.new()\r\nboxplot(x = ss_aceh01[,3:ncol(ss_aceh01)], lwd = 2, yaxt='n', ylim=c(0,1), col = 'white', medlwd=2, cex.axis=0.5)\r\npoints(x = 1:ncol(ss_aceh01[,3:ncol(ss_aceh01)]),apply(X = ss_aceh01[,3:ncol(ss_aceh01)], MARGIN = 2,FUN=mean),pch=21,col='blue3',lwd=2)\r\nfor (i in 1:ncol(ss_aceh01)-2) {\r\n  points(jitter(rep(i, nrow(ss_aceh01))), ss_aceh01[[i+2]], col = \"red\", pch = 16, cex=0.45)\r\n}\r\ntext(x=1:ncol(ss_aceh01[,3:ncol(ss_aceh01)]), y=apply(X = ss_aceh01[,3:ncol(ss_aceh01)], MARGIN = 2, FUN=mean)+0.02, labels= paste0('Mean = ', round(apply(X = ss_aceh01[,3:ncol(ss_aceh01)], MARGIN = 2, FUN=mean),2)), cex=0.5)\r\naxis(side=2, at=seq(0,1,0.1), labels=seq(0,1,0.1), cex.axis=0.8)\r\nsegments(x0 = seq(0,7,0.5), y0 = 0, y1 = 1, lty=2, lwd=0.5,col = 'lightgrey')\r\nsegments(x0 = 0, x1 = 7, y0 = seq(0,1,0.1), lty=2, lwd=0.5,col = 'lightgrey')\r\nmtext(~ italic('Skill Score (SS)'), side = 2, line = 2, cex = 0.8)\r\ntitle(main = paste0('Boxplot Skill Score ZOM : ACEH_01'), line = 0.5)\r\nmtext(~ italic('Periode 2011 - 2020'), side = 1, line = par('usr')[3]-1, col = \"black\", cex = 0.6, at=par('usr')[2]-0.7)\r\nmtext('Init : JAN', side = 3, font=3,line = par('usr')[3]-1, col = \"darkblue\", cex = 0.8, at=par('usr')[2]-0.4)\r\n\r\n\r\n\r\n\\(~\\)\r\n4. RAINFALL WEIGHTING\r\nSeasonal Rainfall Prediction Weighting based on Skill Score\r\n\r\nFrom the highest Skill Score results, we will know the best model for each initial in each ZOM. For season onset prediction, we can use the best model that is already known according to the initial month used as a seasonal prediction of rainfall. From the prediction of rainfall values based on this best model, the season onset can then be determined.\r\n\r\n\r\nAnother method that we can do if we still want to use all the rainfall seasonal prediction model outputs is by weighting each rainfall model output. This weight can be obtained based on the Skill Score value of each model that we have calculated. Mathematically, it can be formulated as follows:\r\n\r\n\\[\\begin{equation}\r\n\\tag{3}\r\n\\text{W}_i = \\frac{SS_i}{\\sum_{j=1}^{n} SS_j}\r\n\\end{equation}\\]\r\n\\[\\begin{equation}\r\n\\tag{4}\r\n\\sum_{i=1}^{n} W_i = 1\r\n\\end{equation}\\]\r\nWhere:\r\n\\[\r\n{SS_i} = {i-}\\text{th model Skill Score, where }{i = 1,2,...,n}\r\n\\]\r\n\\[\r\n{W_i} = {i-}\\text{th model Weight, where }{i = 1,2,...,n}\r\n\\]\r\nSeasonal Rainfall Prediction ZOM 9120 using Skill Score-based weighting\r\n\r\nWe will do the weight calculation as practice. In this case we are using ZOM BALI_11 with the initials February. From the results of the weight calculation (W), if we add up the total is 1.\r\n\r\n\r\n\r\n\r\n\r\nZOM\r\n\r\n\r\nTYPE\r\n\r\n\r\nINIT\r\n\r\n\r\nMME1\r\n\r\n\r\nECMWF_RAW\r\n\r\n\r\nECMWF_COR\r\n\r\n\r\nCFSv2_RAW\r\n\r\n\r\nCFSv2_COR\r\n\r\n\r\nARIMA\r\n\r\n\r\nWARIMA\r\n\r\n\r\n25896\r\n\r\n\r\nBALI_11\r\n\r\n\r\nSS\r\n\r\n\r\nFeb\r\n\r\n\r\n0.4786296\r\n\r\n\r\n0.4334377\r\n\r\n\r\n0.5389604\r\n\r\n\r\n0.0695950\r\n\r\n\r\n0.5097606\r\n\r\n\r\n0.5386813\r\n\r\n\r\n0.4729669\r\n\r\n\r\n258961\r\n\r\n\r\nBALI_11\r\n\r\n\r\nW\r\n\r\n\r\nFeb\r\n\r\n\r\n0.1573388\r\n\r\n\r\n0.1424830\r\n\r\n\r\n0.1771712\r\n\r\n\r\n0.0228778\r\n\r\n\r\n0.1675724\r\n\r\n\r\n0.1770795\r\n\r\n\r\n0.1554773\r\n\r\n\r\n\r\nNext, we will weight the February 2024 initial seasonal rainfall prediction (generally used for dry season prediction). We multiply each model with the weight (W) that we have obtained in the previous weight calculation.\r\n\r\n\r\nSEASONAL RAINFALL PREDICTION DATA INITIAL FEBRUARY 2024\r\n\r\n\r\n\r\nDAS\r\n\r\n\r\nMME1\r\n\r\n\r\nECMWF_RAW\r\n\r\n\r\nECMWF_COR\r\n\r\n\r\nCFSv2_RAW\r\n\r\n\r\nCFSv2_COR\r\n\r\n\r\nARIMA\r\n\r\n\r\nWARIMA\r\n\r\n\r\nFeb I\r\n\r\n\r\n163.8225\r\n\r\n\r\n96.9621\r\n\r\n\r\n131.9956\r\n\r\n\r\n55.9008\r\n\r\n\r\n202.7789\r\n\r\n\r\n107.4265\r\n\r\n\r\n92.3780\r\n\r\n\r\nFeb II\r\n\r\n\r\n72.1478\r\n\r\n\r\n83.7558\r\n\r\n\r\n114.0584\r\n\r\n\r\n29.5072\r\n\r\n\r\n107.0710\r\n\r\n\r\n99.2311\r\n\r\n\r\n92.3780\r\n\r\n\r\nFeb III\r\n\r\n\r\n81.4403\r\n\r\n\r\n75.8253\r\n\r\n\r\n103.3301\r\n\r\n\r\n30.6811\r\n\r\n\r\n111.3555\r\n\r\n\r\n87.2150\r\n\r\n\r\n85.6466\r\n\r\n\r\nMar I\r\n\r\n\r\n25.0803\r\n\r\n\r\n97.1974\r\n\r\n\r\n107.0056\r\n\r\n\r\n49.4504\r\n\r\n\r\n151.6484\r\n\r\n\r\n75.1727\r\n\r\n\r\n84.5403\r\n\r\n\r\nMar II\r\n\r\n\r\n120.4728\r\n\r\n\r\n93.7277\r\n\r\n\r\n103.1808\r\n\r\n\r\n75.5555\r\n\r\n\r\n231.6704\r\n\r\n\r\n74.0638\r\n\r\n\r\n80.1041\r\n\r\n\r\nMar III\r\n\r\n\r\n169.5966\r\n\r\n\r\n85.7359\r\n\r\n\r\n94.4199\r\n\r\n\r\n83.6646\r\n\r\n\r\n256.5225\r\n\r\n\r\n63.1690\r\n\r\n\r\n44.2504\r\n\r\n\r\nApr I\r\n\r\n\r\n29.1713\r\n\r\n\r\n74.2389\r\n\r\n\r\n60.4546\r\n\r\n\r\n68.8359\r\n\r\n\r\n74.1464\r\n\r\n\r\n50.7099\r\n\r\n\r\n40.5221\r\n\r\n\r\nApr II\r\n\r\n\r\n38.4456\r\n\r\n\r\n63.8937\r\n\r\n\r\n52.0237\r\n\r\n\r\n70.8249\r\n\r\n\r\n76.2927\r\n\r\n\r\n50.6072\r\n\r\n\r\n8.5760\r\n\r\n\r\nApr III\r\n\r\n\r\n60.3156\r\n\r\n\r\n55.0750\r\n\r\n\r\n44.8474\r\n\r\n\r\n75.9045\r\n\r\n\r\n81.7458\r\n\r\n\r\n38.5234\r\n\r\n\r\n38.8828\r\n\r\n\r\nMay I\r\n\r\n\r\n23.8206\r\n\r\n\r\n44.4667\r\n\r\n\r\n28.0870\r\n\r\n\r\n72.5172\r\n\r\n\r\n34.3506\r\n\r\n\r\n28.6324\r\n\r\n\r\n10.1355\r\n\r\n\r\nMay II\r\n\r\n\r\n31.2781\r\n\r\n\r\n39.5156\r\n\r\n\r\n24.9615\r\n\r\n\r\n66.9831\r\n\r\n\r\n31.7315\r\n\r\n\r\n24.5754\r\n\r\n\r\n24.9866\r\n\r\n\r\nMay III\r\n\r\n\r\n32.9556\r\n\r\n\r\n29.2346\r\n\r\n\r\n18.4672\r\n\r\n\r\n123.3038\r\n\r\n\r\n58.4087\r\n\r\n\r\n28.1022\r\n\r\n\r\n7.3104\r\n\r\n\r\nJun I\r\n\r\n\r\n19.5028\r\n\r\n\r\n24.1109\r\n\r\n\r\n15.9519\r\n\r\n\r\n60.1589\r\n\r\n\r\n27.3728\r\n\r\n\r\n13.4558\r\n\r\n\r\n7.2317\r\n\r\n\r\nJun II\r\n\r\n\r\n8.7416\r\n\r\n\r\n22.2295\r\n\r\n\r\n14.7116\r\n\r\n\r\n39.5339\r\n\r\n\r\n17.9883\r\n\r\n\r\n12.1809\r\n\r\n\r\n0.0000\r\n\r\n\r\nJun III\r\n\r\n\r\n5.8922\r\n\r\n\r\n14.4046\r\n\r\n\r\n9.5367\r\n\r\n\r\n36.8783\r\n\r\n\r\n16.7778\r\n\r\n\r\n12.9941\r\n\r\n\r\n2.9549\r\n\r\n\r\nJul I\r\n\r\n\r\n10.4091\r\n\r\n\r\n9.8209\r\n\r\n\r\n9.3945\r\n\r\n\r\n32.3297\r\n\r\n\r\n22.2831\r\n\r\n\r\n8.1527\r\n\r\n\r\n2.2763\r\n\r\n\r\nJul II\r\n\r\n\r\n15.2450\r\n\r\n\r\n10.0609\r\n\r\n\r\n9.6385\r\n\r\n\r\n35.1482\r\n\r\n\r\n24.2216\r\n\r\n\r\n5.2905\r\n\r\n\r\n14.9037\r\n\r\n\r\nJul III\r\n\r\n\r\n19.0328\r\n\r\n\r\n10.5429\r\n\r\n\r\n10.0975\r\n\r\n\r\n27.4801\r\n\r\n\r\n18.9454\r\n\r\n\r\n0.0000\r\n\r\n\r\n8.1212\r\n\r\n\r\nAug I\r\n\r\n\r\n1.3834\r\n\r\n\r\n6.5196\r\n\r\n\r\n3.7593\r\n\r\n\r\n22.5320\r\n\r\n\r\n8.8758\r\n\r\n\r\n14.0602\r\n\r\n\r\n13.5241\r\n\r\n\r\nAug II\r\n\r\n\r\n3.0947\r\n\r\n\r\n6.9658\r\n\r\n\r\n4.0088\r\n\r\n\r\n17.2212\r\n\r\n\r\n6.7787\r\n\r\n\r\n12.4973\r\n\r\n\r\n10.8369\r\n\r\n\r\nAug III\r\n\r\n\r\n7.1116\r\n\r\n\r\n6.9975\r\n\r\n\r\n4.0227\r\n\r\n\r\n25.4537\r\n\r\n\r\n9.9893\r\n\r\n\r\n12.2050\r\n\r\n\r\n3.6793\r\n\r\n\r\n\r\nWEIGHTED FOR INITIAL FEBRUARY 2024\r\n\r\n\r\n\r\nDAS\r\n\r\n\r\nMME1\r\n\r\n\r\nECMWF_RAW\r\n\r\n\r\nECMWF_COR\r\n\r\n\r\nCFSv2_RAW\r\n\r\n\r\nCFSv2_COR\r\n\r\n\r\nARIMA\r\n\r\n\r\nWARIMA\r\n\r\n\r\nRRw\r\n\r\n\r\nFeb I\r\n\r\n\r\n25.7756371\r\n\r\n\r\n13.8154471\r\n\r\n\r\n23.3858205\r\n\r\n\r\n1.2788882\r\n\r\n\r\n33.980149\r\n\r\n\r\n19.0230277\r\n\r\n\r\n14.3626839\r\n\r\n\r\n131.621654\r\n\r\n\r\nFeb II\r\n\r\n\r\n11.3516489\r\n\r\n\r\n11.9337743\r\n\r\n\r\n20.2078650\r\n\r\n\r\n0.6750603\r\n\r\n\r\n17.942146\r\n\r\n\r\n17.5717906\r\n\r\n\r\n14.3626839\r\n\r\n\r\n94.044969\r\n\r\n\r\nFeb III\r\n\r\n\r\n12.8137198\r\n\r\n\r\n10.8038132\r\n\r\n\r\n18.3071191\r\n\r\n\r\n0.7019165\r\n\r\n\r\n18.660110\r\n\r\n\r\n15.4439860\r\n\r\n\r\n13.3161039\r\n\r\n\r\n90.046768\r\n\r\n\r\nMar I\r\n\r\n\r\n3.9461045\r\n\r\n\r\n13.8489733\r\n\r\n\r\n18.9583119\r\n\r\n\r\n1.1313171\r\n\r\n\r\n25.412088\r\n\r\n\r\n13.3115419\r\n\r\n\r\n13.1440993\r\n\r\n\r\n89.752436\r\n\r\n\r\nMar II\r\n\r\n\r\n18.9550469\r\n\r\n\r\n13.3546002\r\n\r\n\r\n18.2806675\r\n\r\n\r\n1.7285448\r\n\r\n\r\n38.821568\r\n\r\n\r\n13.1151785\r\n\r\n\r\n12.4543708\r\n\r\n\r\n116.709976\r\n\r\n\r\nMar III\r\n\r\n\r\n26.6841271\r\n\r\n\r\n12.2159049\r\n\r\n\r\n16.7284882\r\n\r\n\r\n1.9140632\r\n\r\n\r\n42.986094\r\n\r\n\r\n11.1859331\r\n\r\n\r\n6.8799336\r\n\r\n\r\n118.594544\r\n\r\n\r\nApr I\r\n\r\n\r\n4.5897776\r\n\r\n\r\n10.5777783\r\n\r\n\r\n10.7108148\r\n\r\n\r\n1.5748150\r\n\r\n\r\n12.424891\r\n\r\n\r\n8.9796822\r\n\r\n\r\n6.3002675\r\n\r\n\r\n55.158026\r\n\r\n\r\nApr II\r\n\r\n\r\n6.0489849\r\n\r\n\r\n9.1037635\r\n\r\n\r\n9.2171020\r\n\r\n\r\n1.6203190\r\n\r\n\r\n12.784552\r\n\r\n\r\n8.9614962\r\n\r\n\r\n1.3333735\r\n\r\n\r\n49.069591\r\n\r\n\r\nApr III\r\n\r\n\r\n9.4899847\r\n\r\n\r\n7.8472491\r\n\r\n\r\n7.9456682\r\n\r\n\r\n1.7365291\r\n\r\n\r\n13.698341\r\n\r\n\r\n6.8217033\r\n\r\n\r\n6.0453936\r\n\r\n\r\n53.584869\r\n\r\n\r\nMay I\r\n\r\n\r\n3.7479048\r\n\r\n\r\n6.3357471\r\n\r\n\r\n4.9762078\r\n\r\n\r\n1.6590351\r\n\r\n\r\n5.756213\r\n\r\n\r\n5.0702102\r\n\r\n\r\n1.5758404\r\n\r\n\r\n29.121158\r\n\r\n\r\nMay II\r\n\r\n\r\n4.9212590\r\n\r\n\r\n5.6302997\r\n\r\n\r\n4.4224592\r\n\r\n\r\n1.5324270\r\n\r\n\r\n5.317324\r\n\r\n\r\n4.3517988\r\n\r\n\r\n3.8848496\r\n\r\n\r\n30.060417\r\n\r\n\r\nMay III\r\n\r\n\r\n5.1851949\r\n\r\n\r\n4.1654324\r\n\r\n\r\n3.2718562\r\n\r\n\r\n2.8209215\r\n\r\n\r\n9.787687\r\n\r\n\r\n4.9763227\r\n\r\n\r\n1.1366014\r\n\r\n\r\n31.344016\r\n\r\n\r\nJun I\r\n\r\n\r\n3.0685473\r\n\r\n\r\n3.4353924\r\n\r\n\r\n2.8262175\r\n\r\n\r\n1.3763042\r\n\r\n\r\n4.586926\r\n\r\n\r\n2.3827459\r\n\r\n\r\n1.1243653\r\n\r\n\r\n18.800499\r\n\r\n\r\nJun II\r\n\r\n\r\n1.3753929\r\n\r\n\r\n3.1673250\r\n\r\n\r\n2.6064720\r\n\r\n\r\n0.9044493\r\n\r\n\r\n3.014343\r\n\r\n\r\n2.1569873\r\n\r\n\r\n0.0000000\r\n\r\n\r\n13.224969\r\n\r\n\r\nJun III\r\n\r\n\r\n0.9270717\r\n\r\n\r\n2.0524101\r\n\r\n\r\n1.6896287\r\n\r\n\r\n0.8436949\r\n\r\n\r\n2.811496\r\n\r\n\r\n2.3009883\r\n\r\n\r\n0.4594199\r\n\r\n\r\n11.084710\r\n\r\n\r\nJul I\r\n\r\n\r\n1.6377554\r\n\r\n\r\n1.3993109\r\n\r\n\r\n1.6644350\r\n\r\n\r\n0.7396329\r\n\r\n\r\n3.734033\r\n\r\n\r\n1.4436758\r\n\r\n\r\n0.3539130\r\n\r\n\r\n10.972756\r\n\r\n\r\nJul II\r\n\r\n\r\n2.3986301\r\n\r\n\r\n1.4335068\r\n\r\n\r\n1.7076647\r\n\r\n\r\n0.8041140\r\n\r\n\r\n4.058872\r\n\r\n\r\n0.9368389\r\n\r\n\r\n2.3171873\r\n\r\n\r\n13.656814\r\n\r\n\r\nJul III\r\n\r\n\r\n2.9945981\r\n\r\n\r\n1.5021836\r\n\r\n\r\n1.7889863\r\n\r\n\r\n0.6286846\r\n\r\n\r\n3.174726\r\n\r\n\r\n0.0000000\r\n\r\n\r\n1.2626624\r\n\r\n\r\n11.351841\r\n\r\n\r\nAug I\r\n\r\n\r\n0.2176625\r\n\r\n\r\n0.9289319\r\n\r\n\r\n0.6660397\r\n\r\n\r\n0.5154829\r\n\r\n\r\n1.487339\r\n\r\n\r\n2.4897728\r\n\r\n\r\n2.1026908\r\n\r\n\r\n8.407920\r\n\r\n\r\nAug II\r\n\r\n\r\n0.4869164\r\n\r\n\r\n0.9925078\r\n\r\n\r\n0.7102440\r\n\r\n\r\n0.3939834\r\n\r\n\r\n1.135923\r\n\r\n\r\n2.2130153\r\n\r\n\r\n1.6848922\r\n\r\n\r\n7.617482\r\n\r\n\r\nAug III\r\n\r\n\r\n1.1189307\r\n\r\n\r\n0.9970245\r\n\r\n\r\n0.7127066\r\n\r\n\r\n0.5823250\r\n\r\n\r\n1.673931\r\n\r\n\r\n2.1612549\r\n\r\n\r\n0.5720477\r\n\r\n\r\n7.818221\r\n\r\n\r\n\r\nThe seasonal rainfall prediction value that we will use is the total of each weighted model in each dasarian. In this case we can see in the yellow column.\r\n\r\n\r\n\r\n\r\n\r\nJolliffe, I. T., and D. B. Stephenson. 2011. Forecast Verification: A Practitioner’s Guide in Atmospheric Science. Wiley. https://books.google.co.id/books?id=sgwIEAAAQBAJ.\r\n\r\n\r\nMurphy, Allan H. 1993. “What Is a Good Forecast? An Essay on the Nature of Goodness in Weather Forecasting.” Weather and Forecasting 8 (2): 281–93. https://doi.org/10.1175/1520-0434(1993)008<0281:WIAGFA>2.0.CO;2.\r\n\r\n\r\nWilks, Daniel S. 2011. Statistical Methods in the Atmospheric Sciences. Amsterdam; Boston: Elsevier Academic Press. https://www.amazon.com/Statistical-Atmospheric-Sciences-International-Geophysics/dp/0123850223/ref=pd_bxgy_14_img_3?_encoding=UTF8&psc=1&refRID=ESPQQ0R2PB1TP1VJSGCZ.\r\n\r\n\r\nWWRP. 2017. “WWRP/WGNE Joint Working Group on Forecast Verification Research.” https://www.cawcr.gov.au/projects/verification.\r\n\r\n\r\nXiaoli Yang, Yuqian Wang, Xiaohan Yu, and Justin Sheffield. 2020. “The Optimal Multimodel Ensemble of Bias-Corrected CMIP5 Climate Models over China.” Journal of Hydrometeorology 21 (4): 845–63. https://doi.org/10.1175/JHM-D-19-0141.1.\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2024-10-10-best-rainfall-prediction-model-based-on-skill-score/zom_type.png",
    "last_modified": "2024-11-10T11:43:16+07:00",
    "input_file": {}
  }
]
